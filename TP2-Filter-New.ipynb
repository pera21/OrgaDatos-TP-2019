{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as datetime\n",
    "import datetime \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maximiliano/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (13,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/maximiliano/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (16,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/maximiliano/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (4,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "events = pd.read_csv(\"events.csv.gzip\", compression='gzip')\n",
    "clicks = pd.read_csv(\"clicks.csv.gzip\", compression='gzip')\n",
    "installs = pd.read_csv(\"installs.csv.gzip\", compression='gzip')\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformo a datetime la fecha y las posiciones de clicks en floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs['created'] = pd.to_datetime(installs['created'])\n",
    "events['date'] = pd.to_datetime(events['date'])\n",
    "clicks['created'] = pd.to_datetime(clicks['created'])\n",
    "\n",
    "clicks['touchX_float'] = clicks['touchX'].astype('float64')\n",
    "clicks['touchY_float'] = clicks['touchY'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs['date_seconds_level'] = installs['created'].astype('datetime64[s]')\n",
    "events['date_seconds_level'] = events['date'].astype('datetime64[s]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrego diferencias entre installs de la misma aplicacion para el mismo usuario (para borrar posibles errores de la tracking platform luego)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs['seconds_to_prev_install'] = installs.sort_values(['ref_hash', 'created'], ascending=True).groupby(['ref_hash', 'application_id'])['created'].diff()\n",
    "installs['seconds_to_prev_install'] = installs['seconds_to_prev_install']/np.timedelta64(1, 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elimino de installs las instalaciones con menos de un segundo de diferencia para el mismo usuario y misma applicacion (las suponemos error de tracking platform) (22077 installs menos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs = installs.loc[(installs['seconds_to_prev_install'] > 1) | pd.isnull(installs['seconds_to_prev_install'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Busco los installs que no se corresponden con un evento (un install deberia tener un evento en la tabla events para esa fecha). Para ellos genero un evento (774 eventos nuevos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs_with_events = pd.merge(events, installs, on=['ref_hash', 'date_seconds_level', 'application_id'])\n",
    "installs_with_events['install_with_event'] = True\n",
    "installs = pd.merge(installs, installs_with_events[['ref_hash', 'date_seconds_level', 'application_id', 'install_with_event']], on=['ref_hash', 'date_seconds_level', 'application_id'], how='left')\n",
    "installs.head()\n",
    "installs.loc[installs['install_with_event'] != True, 'install_with_event'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maximiliano/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Creo el evento por cada install no correspondido (solo los installs implicitos tienen un evento correspondiente)\n",
    "events = pd.concat([events, installs.loc[(installs['install_with_event'] == False) & (installs['implicit'] == True), ['ref_hash', 'created', 'application_id']]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.loc[pd.isnull(events['date']), 'date'] = pd.to_datetime(events['created'])\n",
    "events.drop(['created'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrego columnas a events, clicks y a installs para poder clasificar despues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs['install_day'] = installs['created'].dt.day\n",
    "events['event_day'] = events['date'].dt.day\n",
    "clicks['click_day'] = clicks['created'].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculo la distancia de los clicks a la cruz de cierre de la impresion (basandonos en un heatmap realizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks['distanceToCloseButton'] = np.sqrt(abs(clicks['touchX_float'] - 0.95)**2 + abs(clicks['touchY_float'] - 0.05)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creando el dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maximiliano/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/maximiliano/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/maximiliano/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/home/maximiliano/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/maximiliano/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/maximiliano/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/maximiliano/miniconda3/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "df_installs = {}\n",
    "df_events = {}\n",
    "df_clicks = {}\n",
    "devices = {}\n",
    "for i in range(18, 22):\n",
    "#for i in range(24, 25):\n",
    "    windowStartDate = datetime.datetime(2019, 4, i)\n",
    "    windowEndDate = datetime.datetime(2019, 4, i + 3)\n",
    "    df_installs[i - 18] = installs.loc[(installs['created'] >= windowStartDate) & (windowEndDate >= installs['created'])]\n",
    "    df_events[i - 18] = events.loc[(events['date'] >= windowStartDate) & (windowEndDate >= events['date'])]\n",
    "    df_clicks[i - 18] = clicks.loc[(clicks['created'] >= windowStartDate) & (windowEndDate >= clicks['created'])]\n",
    "    \n",
    "    #Calculando diferencias de tiempos para installs, eventos y clicks para un mismo usuario y esa ventana\n",
    "    df_installs[i - 18]['diff_to_prev_install'] = df_installs[i - 18].sort_values('created', ascending=True).groupby('ref_hash')['created'].diff()\n",
    "    df_installs[i - 18]['diff_to_prev_install'] = df_installs[i - 18]['diff_to_prev_install']/np.timedelta64(1, 's')\n",
    "    df_events[i - 18]['diff_to_prev_event'] = df_events[i - 18].sort_values('date', ascending=True).groupby('ref_hash')['date'].diff()\n",
    "    df_events[i - 18]['diff_to_prev_event'] = df_events[i - 18]['diff_to_prev_event']/np.timedelta64(1, 's')\n",
    "    df_clicks[i - 18]['diff_to_prev_click'] = df_clicks[i - 18].sort_values('created', ascending=True).groupby('ref_hash')['created'].diff()\n",
    "    df_clicks[i - 18]['diff_to_prev_click'] = df_clicks[i - 18]['diff_to_prev_click']/np.timedelta64(1, 's')\n",
    "    \n",
    "    #Completo los NaN con diferencias al inicio de la ventana (los NaN son aquellos que no tienen un registro previo => es el primer install/event/click para el usuario en la ventana)\n",
    "    df_installs[i - 18].loc[pd.isnull(df_installs[i - 18]['diff_to_prev_install']), 'diff_to_prev_install'] = (df_installs[i - 18]['created'] - windowStartDate)/np.timedelta64(1, 's')\n",
    "    df_events[i - 18].loc[pd.isnull(df_events[i - 18]['diff_to_prev_event']), 'diff_to_prev_event'] = (df_events[i - 18]['date'] - windowStartDate)/np.timedelta64(1, 's')\n",
    "    df_clicks[i - 18].loc[pd.isnull(df_clicks[i - 18]['diff_to_prev_click']), 'diff_to_prev_click'] = (df_clicks[i - 18]['created'] - windowStartDate)/np.timedelta64(1, 's')\n",
    "                                                                                                     \n",
    "    #Creo un dataframe de dispositivos con todos los dispositivos que tienen eventos para esa ventana\n",
    "    devices[i - 18] = pd.DataFrame(df_events[i - 18]['ref_hash'].unique())\n",
    "    \n",
    "    #Agrego los segundos a la proxima conversion (desde el inicio de la ventana)\n",
    "    next_window_installs = installs.loc[(installs['created'] >= datetime.datetime(2019, 4, i + 3)) & (datetime.datetime(2019, 4, i + 6) >= installs['created'])]\n",
    "    devices[i - 18].columns = ['ref_hash']\n",
    "    devices[i - 18] = pd.merge(devices[i - 18], next_window_installs.groupby('ref_hash')['created'].min().reset_index(), on='ref_hash', how='left')\n",
    "    devices[i - 18].rename(columns = {'created':'seconds_to_conversion'}, inplace=True)\n",
    "    devices[i - 18]['seconds_to_conversion'] = (devices[i - 18]['seconds_to_conversion'] - windowEndDate)/np.timedelta64(1, 's')\n",
    "    \n",
    "    #Completo los seconds_to_conversion de los que no convirtieron con el valor correspondiente a 3 dias en segundos\n",
    "    devices[i - 18].loc[pd.isnull(devices[i - 18]['seconds_to_conversion']), 'seconds_to_conversion'] = 259200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separo los dataframe para obtener las distintas ventanas con las cuales entrenar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrego features para cada dataframe de devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 4):\n",
    "#for i in range(6, 7):\n",
    "    #Porcentaje de installs implicitos y no implicitos en el periodo + total installs en el periodo\n",
    "    installs_by_implicit = pd.pivot_table(df_installs[i], index='ref_hash', columns='implicit', values='created', aggfunc='count', fill_value=0, margins=True).reset_index()\n",
    "    installs_by_implicit.drop(installs_by_implicit.tail(1).index, inplace=True) #Elimino el margin creado por pivot_table\n",
    "    installs_by_implicit.columns = ['ref_hash', 'installs_not_implicit', 'installs_implicit', 'total_installs']\n",
    "    installs_by_implicit['ref_hash'] = installs_by_implicit['ref_hash'].astype('int64')\n",
    "    installs_by_implicit['installs_not_implicit_percent'] = installs_by_implicit['installs_not_implicit']/installs_by_implicit['total_installs']\n",
    "    installs_by_implicit['installs_implicit_percent'] = installs_by_implicit['installs_implicit']/installs_by_implicit['total_installs']\n",
    "    devices[i] = pd.merge(devices[i], installs_by_implicit[['ref_hash', 'installs_not_implicit_percent', 'installs_implicit_percent']], on='ref_hash', how='left')\n",
    "    \n",
    "    #Porcentaje de installs por dia en el periodo\n",
    "    installs_by_day = pd.pivot_table(df_installs[i], index='ref_hash', columns='install_day', values='created', aggfunc='count', fill_value=0, margins=True).reset_index()\n",
    "    installs_by_day.drop(installs_by_day.tail(1).index, inplace=True) #Elimino el margin creado por pivot_table\n",
    "    installs_by_day.columns = ['ref_hash', 'installs_day_1', 'installs_day_2', 'installs_day_3', 'total_installs']\n",
    "    installs_by_day['ref_hash'] = installs_by_day['ref_hash'].astype('int64')\n",
    "    installs_by_day['installs_day_1_percent'] = installs_by_day['installs_day_1']/installs_by_day['total_installs']\n",
    "    installs_by_day['installs_day_2_percent'] = installs_by_day['installs_day_2']/installs_by_day['total_installs']\n",
    "    installs_by_day['installs_day_3_percent'] = installs_by_day['installs_day_3']/installs_by_day['total_installs']\n",
    "    devices[i] = pd.merge(devices[i], installs_by_day, on='ref_hash', how='left')\n",
    "    devices[i]['total_installs_normalized'] = devices[i]['total_installs']/(devices[i]['total_installs'].max())\n",
    "    del installs_by_day\n",
    "    \n",
    "    #Porcentaje de eventos por dia en el periodo + total eventos\n",
    "    events_by_day = pd.pivot_table(df_events[i], index='ref_hash', columns='event_day', values='date', aggfunc='count', fill_value=0, margins=True).reset_index()\n",
    "    events_by_day.drop(events_by_day.tail(1).index, inplace=True) #Elimino el margin creado por pivot_table\n",
    "    events_by_day.columns = ['ref_hash', 'events_day_1', 'events_day_2', 'events_day_3', 'total_events']\n",
    "    events_by_day['ref_hash'] = events_by_day['ref_hash'].astype('int64')\n",
    "    events_by_day['events_day_1_percent'] = events_by_day['events_day_1']/events_by_day['total_events']\n",
    "    events_by_day['events_day_2_percent'] = events_by_day['events_day_2']/events_by_day['total_events']\n",
    "    events_by_day['events_day_3_percent'] = events_by_day['events_day_3']/events_by_day['total_events']\n",
    "    devices[i] = pd.merge(devices[i], events_by_day, on='ref_hash', how='left')\n",
    "    devices[i]['total_events_normalized'] = devices[i]['total_events']/(devices[i]['total_events'].max())\n",
    "    del events_by_day\n",
    "    \n",
    "    #Calculo el porcentaje de eventos hechos a traves de wifi (esto puede influir en un futuro install)\n",
    "    events_by_wifi = pd.pivot_table(df_events[i], index='ref_hash', columns='wifi', values='date', aggfunc='count', fill_value=0).reset_index()\n",
    "    events_by_wifi['events_on_wifi_percent'] = events_by_wifi[True]/(events_by_wifi[True] + events_by_wifi[False])\n",
    "    devices[i] = pd.merge(devices[i], events_by_wifi[['ref_hash', 'events_on_wifi_percent']], on='ref_hash', how='left')\n",
    "    del events_by_wifi\n",
    "    \n",
    "    #Porcentaje de clicks por dia en el periodo\n",
    "    clicks_by_day = pd.pivot_table(df_clicks[i], index='ref_hash', columns='click_day', values='created', aggfunc='count', fill_value=0, margins=True).reset_index()\n",
    "    clicks_by_day.drop(clicks_by_day.tail(1).index, inplace=True) #Elimino el margin creado por pivot_table\n",
    "    clicks_by_day.columns = ['ref_hash', 'clicks_day_1', 'clicks_day_2', 'clicks_day_3', 'total_clicks']\n",
    "    clicks_by_day['ref_hash'] = clicks_by_day['ref_hash'].astype('int64')\n",
    "    clicks_by_day['clicks_day_1_percent'] = clicks_by_day['clicks_day_1']/clicks_by_day['total_clicks']\n",
    "    clicks_by_day['clicks_day_2_percent'] = clicks_by_day['clicks_day_2']/clicks_by_day['total_clicks']\n",
    "    clicks_by_day['clicks_day_3_percent'] = clicks_by_day['clicks_day_3']/clicks_by_day['total_clicks']\n",
    "    devices[i] = pd.merge(devices[i], clicks_by_day, on='ref_hash', how='left')\n",
    "    devices[i]['total_clicks_normalized'] = devices[i]['total_clicks']/(devices[i]['total_clicks'].max())\n",
    "    del clicks_by_day\n",
    "    \n",
    "    #Trabajando con la posicion de los clicks (promedio de distancia al boton de cerrar publicidad)\n",
    "    devices[i] = pd.merge(devices[i], df_clicks[i].loc[(~np.isnan(df_clicks[i]['touchX_float'])) & (~np.isnan(df_clicks[i]['touchY_float']))].groupby('ref_hash')['distanceToCloseButton'].mean().reset_index(), on='ref_hash', how='left')\n",
    "    devices[i].rename(columns = {'distanceToCloseButton':'mean_distance_to_close_button'}, inplace=True)\n",
    "    \n",
    "    #Agregando promedios y desvios de los tiempos entre installs, events y clicks para un mismo usuario en esa ventana\n",
    "    installs_grouped = df_installs[i].groupby('ref_hash').agg({'diff_to_prev_install': ['mean', 'std']}).reset_index()\n",
    "    installs_grouped.columns = ['ref_hash', 'mean_diff_between_installs', 'std_diff_between_installs']\n",
    "    devices[i] = pd.merge(devices[i], installs_grouped, on='ref_hash', how='left')\n",
    "    #Completo el mean_diff_between_installs con 259200 (3 dias en segundos) y el std_diff_between_installs con 0 (el desvio estandar de una muestra unica es 0)\n",
    "    devices[i]['mean_diff_between_installs'].fillna(259200, inplace=True)\n",
    "    devices[i]['std_diff_between_installs'].fillna(0, inplace=True)\n",
    "    del installs_grouped\n",
    "    \n",
    "    events_grouped = df_events[i].groupby('ref_hash').agg({'diff_to_prev_event': ['mean', 'std']}).reset_index()\n",
    "    events_grouped.columns = ['ref_hash', 'mean_diff_between_events', 'std_diff_between_events']\n",
    "    devices[i] = pd.merge(devices[i], events_grouped, on='ref_hash', how='left')\n",
    "    #Completo el mean_diff_between_events con 259200 (3 dias en segundos) y el std_diff_between_events con 0 (el desvio estandar de una muestra unica es 0)\n",
    "    devices[i]['mean_diff_between_events'].fillna(259200, inplace=True)\n",
    "    devices[i]['std_diff_between_events'].fillna(0, inplace=True)\n",
    "    del events_grouped\n",
    "    \n",
    "    clicks_grouped = df_clicks[i].groupby('ref_hash').agg({'diff_to_prev_click': ['mean', 'std']}).reset_index()\n",
    "    clicks_grouped.columns = ['ref_hash', 'mean_diff_between_clicks', 'std_diff_between_clicks']\n",
    "    devices[i] = pd.merge(devices[i], clicks_grouped, on='ref_hash', how='left')\n",
    "    #Completo el mean_diff_between_clicks con 259200 (3 dias en segundos) y el std_diff_between_clicks con 0 (el desvio estandar de una muestra unica es 0)\n",
    "    devices[i]['mean_diff_between_clicks'].fillna(259200, inplace=True)\n",
    "    devices[i]['std_diff_between_clicks'].fillna(0, inplace=True)\n",
    "    del clicks_grouped\n",
    "    \n",
    "    #Completo la distancia al boton de cerrar con el promedio de la columna\n",
    "    devices[i]['mean_distance_to_close_button'].fillna(devices[i]['mean_distance_to_close_button'].mean(), inplace=True)\n",
    "    \n",
    "    #Completo los nan con 0 todas las columnas restantes\n",
    "    devices[i].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Libero memoria\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrego informacion del dispositivo. Esto puede tardar -- Eliminados los de events porque habia pocos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agregado os_minor para devices0\n",
      "Agregado os_major para devices0\n",
      "Agregado ref_type para devices0\n",
      "Agregado brand para devices0\n",
      "Agregado time_to_click_mean para devices0\n",
      "Completados los valores nulos de time_to_click para devices0\n",
      "Completados los valores nulos de time_to_click para devices0\n",
      "Completados los valores nulos de os_minor para devices0\n",
      "Completados los valores nulos de os_major para devices0\n",
      "Completados los valores nulos de brand para devices0\n",
      "----------\n",
      "Agregado os_minor para devices1\n",
      "Agregado os_major para devices1\n",
      "Agregado ref_type para devices1\n",
      "Agregado brand para devices1\n",
      "Agregado time_to_click_mean para devices1\n",
      "Completados los valores nulos de time_to_click para devices1\n",
      "Completados los valores nulos de time_to_click para devices1\n",
      "Completados los valores nulos de os_minor para devices1\n",
      "Completados los valores nulos de os_major para devices1\n",
      "Completados los valores nulos de brand para devices1\n",
      "----------\n",
      "Agregado os_minor para devices2\n",
      "Agregado os_major para devices2\n",
      "Agregado ref_type para devices2\n",
      "Agregado brand para devices2\n",
      "Agregado time_to_click_mean para devices2\n",
      "Completados los valores nulos de time_to_click para devices2\n",
      "Completados los valores nulos de time_to_click para devices2\n",
      "Completados los valores nulos de os_minor para devices2\n",
      "Completados los valores nulos de os_major para devices2\n",
      "Completados los valores nulos de brand para devices2\n",
      "----------\n",
      "Agregado os_minor para devices3\n",
      "Agregado os_major para devices3\n",
      "Agregado ref_type para devices3\n",
      "Agregado brand para devices3\n",
      "Agregado time_to_click_mean para devices3\n",
      "Completados los valores nulos de time_to_click para devices3\n",
      "Completados los valores nulos de time_to_click para devices3\n",
      "Completados los valores nulos de os_minor para devices3\n",
      "Completados los valores nulos de os_major para devices3\n",
      "Completados los valores nulos de brand para devices3\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "def get_most_frequent_value(s):\n",
    "    return np.nan if s.isnull().all() else s.value_counts().index[0]\n",
    "\n",
    "for i in range(0, 4):\n",
    "#for i in range(6, 7):\n",
    "    #Agrego los valores mas frecuentes para device_model, device_brand, ref_type y device_os en events\n",
    "    #info_events = df_events[i].groupby('ref_hash')\n",
    "    #devices_info_events = info_events['device_model'].apply(get_most_frequent_value).reset_index()\n",
    "    #print('Agregado device_model para devices{}'.format(i))\n",
    "    #devices_info_events['device_brand'] = info_events['device_brand'].apply(get_most_frequent_value).reset_index()['device_brand']\n",
    "    #print('Agregado device_brand para devices{}'.format(i))\n",
    "    #devices_info_events['ref_type'] = info_events['ref_type'].apply(get_most_frequent_value).reset_index()['ref_type']\n",
    "    #print('Agregado ref_type para devices{}'.format(i))\n",
    "    #devices_info_events['device_os'] = info_events['device_os'].apply(get_most_frequent_value).reset_index()['device_os']\n",
    "    #print('Agregado device_os para devices{}'.format(i))\n",
    "    #devices[i] = pd.merge(devices[i], devices_info_events, on='ref_hash', how='left')\n",
    "    #del info_events, devices_info_events\n",
    "    \n",
    "    #Agrego los valores mas frecuentes para os_minor y os_major en clicks\n",
    "    info_clicks = df_clicks[i].groupby('ref_hash')\n",
    "    devices_info_clicks = info_clicks['os_minor'].apply(get_most_frequent_value).reset_index()\n",
    "    print('Agregado os_minor para devices{}'.format(i))\n",
    "    devices_info_clicks['os_major'] = info_clicks['os_major'].apply(get_most_frequent_value).reset_index()['os_major']\n",
    "    print('Agregado os_major para devices{}'.format(i))\n",
    "    devices_info_clicks['ref_type'] = info_clicks['ref_type'].apply(get_most_frequent_value).reset_index()['ref_type']\n",
    "    print('Agregado ref_type para devices{}'.format(i))\n",
    "    devices_info_clicks['brand'] = info_clicks['brand'].apply(get_most_frequent_value).reset_index()['brand']\n",
    "    print('Agregado brand para devices{}'.format(i))\n",
    "    devices_info_clicks['time_to_click_mean'] = info_clicks['timeToClick'].mean().reset_index()['timeToClick']\n",
    "    print('Agregado time_to_click_mean para devices{}'.format(i))\n",
    "    devices[i] = pd.merge(devices[i], devices_info_clicks, on='ref_hash', how='left')\n",
    "    del info_clicks, devices_info_clicks\n",
    "    \n",
    "    #Completo la columna time_to_click_mean con el time_to_click_mean promedio\n",
    "    devices[i]['time_to_click_mean'].fillna(devices[i]['time_to_click_mean'].mean(), inplace=True)\n",
    "    print('Completados los valores nulos de time_to_click para devices{}'.format(i))\n",
    "    \n",
    "    #Completo la columna ref_type con el ref_type mas comun\n",
    "    devices[i]['ref_type'].fillna(devices[i]['ref_type'].value_counts().index[0], inplace=True)\n",
    "    print('Completados los valores nulos de time_to_click para devices{}'.format(i))\n",
    "    \n",
    "    #Completo la columna os_minor con el os_minor mas comun\n",
    "    devices[i]['os_minor'].fillna(devices[i]['os_minor'].value_counts().index[0], inplace=True)\n",
    "    print('Completados los valores nulos de os_minor para devices{}'.format(i))\n",
    "    \n",
    "    #Completo la columna os_major con el os_major mas comun\n",
    "    devices[i]['os_major'].fillna(devices[i]['os_major'].value_counts().index[0], inplace=True)\n",
    "    print('Completados los valores nulos de os_major para devices{}'.format(i))\n",
    "    \n",
    "    #Completo la columna brand con el brand mas comun\n",
    "    devices[i]['brand'].fillna(devices[i]['brand'].value_counts().index[0], inplace=True)\n",
    "    print('Completados los valores nulos de brand para devices{}'.format(i))\n",
    "    \n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generado el archivo devices_featured0.csv\n",
      "Generado el archivo devices_featured1.csv\n",
      "Generado el archivo devices_featured2.csv\n",
      "Generado el archivo devices_featured3.csv\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 4):\n",
    "#for i in range(6, 7):\n",
    "    devices[i].to_csv('devices_featured{}.csv'.format(i), header=True, index=None)\n",
    "    print('Generado el archivo devices_featured{}.csv'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Este no es el archivo de features final. Para generar el archivo final hay que correr el otro notebook que lo mergea con los datos de auctions (no me da la capacidad de procesamiento para ejecutar todo en un mismo notebook)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
